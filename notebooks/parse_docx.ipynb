{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг и анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/urev/projects/master-medicine/\")\n",
    "    \n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import datetime as dt\n",
    "import dataclasses\n",
    "\n",
    "import requests\n",
    "import typing as t\n",
    "import yaml\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DIR_HOME = str(Path.home())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "from docx.api import Document\n",
    "\n",
    "from parser.main import save"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "@dataclasses.dataclass\n",
    "class ParseResult:\n",
    "    folder_name: str\n",
    "    dfs: t.List[t.List[pd.DataFrame]]\n",
    "    skipped_dfs: t.List"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def create_dataframe_from_rows(table) -> pd.DataFrame:\n",
    "    data = []\n",
    "    \n",
    "    keys = None\n",
    "    for i, row in enumerate(table.rows):\n",
    "        text = (cell.text for cell in row.cells)\n",
    "    \n",
    "        if i == 0:\n",
    "            keys = tuple(text)\n",
    "            continue\n",
    "        row_data = dict(zip(keys, text))\n",
    "        data.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def processing_name(name: str) -> str:\n",
    "    \"\"\"Подпись перед таблицей может быть на нескольких строках, пока дропнем всё кроме первой строки\"\"\"\n",
    "    # return name.lower().split(\"\\n\")[0].strip()\n",
    "    return name.lower().replace(\"\\n\", \" \")\n",
    "\n",
    "def processing_folder_name(raw_folder_name: str) -> str:\n",
    "    folder_name = re.findall(r\"\\d\\.\\s+(.*)\", raw_folder_name)\n",
    "    if not folder_name:\n",
    "        return raw_folder_name\n",
    "    else:\n",
    "        return folder_name[-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def get_docx(path: str) -> t.List[str]:\n",
    "    for f in sorted(os.listdir(path)):\n",
    "        if not \"R\" in f or not f.endswith(\"docx\"):\n",
    "            continue\n",
    "        yield os.path.join(path, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "[*get_docx(\"../raw/2021/\")]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "docx_file = \"/home/urev/projects/master-medicine/raw/2013/R-1.docx\"\n",
    "\n",
    "def get_dfs_from_docx(docx_file: str) -> ParseResult:\n",
    "    \"\"\"\n",
    "    Таблицы бывают двух видов:\n",
    "    - узкие с продолжением в высоту (у таких подписано 'Продолжение табл. X.X') - эти автоматически склеятся\n",
    "    - широкие с продолжением в ширину (такие автоматически не парсятся, их надо клеить). Чтобы корректно склеить необходимо добавить разметку в файл:\n",
    "     - Поправить наименование таблицы, тк скорее всего оно тоже широкое и разделено на две части\n",
    "     - таблицы именуются по имени главной, например, 2.76 + следующая нумерация через точку -> 2.76.1\n",
    "     - новая таблица (фактически часть по высоте) обозначается как 2.76.1\n",
    "     - её вертикальное продолжение помечается как ВЕРТИКАЛЬНОЕ продолжение табл. 2.76.1\n",
    "\n",
    "    При такой разметке: узкие таблицы сами склеятся в одну общую, широкие таблицы склеятся по ширине, \n",
    "    по высоте надо будет клеить после (2.76 + 2.76.1 + 2.76.2 и тд)\n",
    "    \"\"\"\n",
    "    document = Document(docx_file)\n",
    "    \n",
    "    dfs = {}\n",
    "    last_obj_stack = []\n",
    "    last_table_obj = None\n",
    "    raw_folder_name = None\n",
    "    skipped_dfs = {}\n",
    "    \n",
    "    for idx, c in enumerate(document.sections[0].iter_inner_content()):\n",
    "        if isinstance(c, Paragraph) and idx == 0:\n",
    "            raw_folder_name = c.text\n",
    "            print(f\"raw_folder_name: {raw_folder_name}\")\n",
    "        if isinstance(c, Paragraph):\n",
    "            # print(f\"--> {c.text}\")\n",
    "            pass\n",
    "        if isinstance(c, Table):\n",
    "            tmp = create_dataframe_from_rows(table=c)\n",
    "    \n",
    "            last_obj = last_obj_stack.pop()\n",
    "            name = last_obj.text.lower()\n",
    "            print(f\"--> Таблица: {name}\")\n",
    "    \n",
    "            pattern_name = \"\\d\\.\\d+\"\n",
    "\n",
    "            if \"пропуск\" in name:\n",
    "                print(f\"SKIP, обнаружена разметка пропуска: {name}\")\n",
    "                tmp.name = name\n",
    "\n",
    "                skipped_dfs[tmp.name] = tmp\n",
    "                \n",
    "                display(tmp.head())\n",
    "                continue\n",
    "            \n",
    "            if re.findall(pattern_name, name):\n",
    "                table_number = re.findall(pattern_name, name)[-1]\n",
    "                print(f\"✅ В имени таблицы (объект перед таблицей) есть цифры: {table_number} -> это или исходная таблица или продолжение!\")\n",
    "            else:\n",
    "                print(f\"🔴 В имени таблицы (объект перед таблицей) нет цифр, попытка взять еще один объект из стека (может быть имя на нескольких строках)\")\n",
    "                if last_obj_stack != []:\n",
    "                    # если стек не пустой\n",
    "                    last_obj = last_obj_stack.pop()\n",
    "\n",
    "                    if isinstance(last_obj, Table):\n",
    "                        print(f\"👀Предыдущий объект = таблица, СКОРЕЕ ВСЕГО НУЖНА РАЗМЕТКА!\")\n",
    "                    elif isinstance(last_obj, Paragraph):\n",
    "                        print(f\"👀 Предыдущий объект = параграф с текстом, извлекаем имя....\")\n",
    "                    \n",
    "                        name = last_obj.text.lower()\n",
    "                        if not re.findall(pattern_name, name):\n",
    "                            print(f\"⛔️ В предыдущем объекте, так же нет цифр, эта таблица нам не подходит! name: {name}\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(f\"✅ Имя таблицы извлечено: {name}\")\n",
    "                else:\n",
    "                    name = \"unknown\"\n",
    "                    print(\"⛔️ Стек пустой!\")\n",
    "                print(f\"☝️ В предыдущем obj нет цифр, берем следующий из стека (или 'unknown'), имя таблицы: {name}\")\n",
    "                \n",
    "            tmp.name = processing_name(name)\n",
    "            \n",
    "            if getattr(last_obj, \"text\") and \"продолжение\" in last_obj.text.lower() and \"вертикальное\" not in last_obj.text.lower():\n",
    "                print(f\"\\t--> Продолжение таблицы: {last_table_obj.name}\")\n",
    "                tmp = pd.concat([last_table_obj, tmp])\n",
    "                tmp.name = last_table_obj.name\n",
    "                display(tmp.sample(5))\n",
    "            elif getattr(last_obj, \"text\") and \"вертикальное\" in last_obj.text.lower():\n",
    "                print(f\"🔫 Это вертикальное продолжение таблицы: {last_table_obj.name}\")\n",
    "                tmp = pd.concat([last_table_obj, tmp], axis=\"columns\")\n",
    "                tmp.name = last_table_obj.name\n",
    "                display(tmp.sample(5))\n",
    "            else:\n",
    "                display(tmp.head())\n",
    "    \n",
    "            dfs[tmp.name] = tmp\n",
    "            \n",
    "            last_table_obj = tmp\n",
    "    \n",
    "        last_obj_stack.append(c)\n",
    "\n",
    "    return ParseResult(\n",
    "        folder_name=processing_folder_name(raw_folder_name),\n",
    "        dfs=[[df] for df in dfs.values()],\n",
    "        skipped_dfs=[[df] for df in skipped_dfs.values()]\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "_parse_obj = get_dfs_from_docx(docx_file=\"../raw/2015/R-1.docx\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "_parse_obj.folder_name"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "year = 2021\n",
    "for doc_path in get_docx(f\"../raw/{year}/\"):\n",
    "    if re.match(r'.*r-[8-9].*', doc_path.lower()):\n",
    "        continue\n",
    "    print(doc_path)\n",
    "    parse_obj = get_dfs_from_docx(docx_file=doc_path)\n",
    "\n",
    "    folder_name = doc_path.split(\"/\")[-1].split(\".\")[0].lower() if not parse_obj.folder_name else parse_obj.folder_name\n",
    "\n",
    "    for dfs in (parse_obj.dfs,\n",
    "               parse_obj.skipped_dfs):\n",
    "        save(list_of_dfs=dfs,\n",
    "             year=year,\n",
    "             folder=f\"../src/{year}/{folder_name}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
