{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/urev/projects/master-medicine/\")\n",
    "    \n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import datetime as dt\n",
    "import dataclasses\n",
    "\n",
    "import requests\n",
    "import typing as t\n",
    "import yaml\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DIR_HOME = str(Path.home())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "from docx.api import Document\n",
    "\n",
    "from parser.main import save"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "@dataclasses.dataclass\n",
    "class ParseResult:\n",
    "    folder_name: str\n",
    "    dfs: t.List[t.List[pd.DataFrame]]\n",
    "    skipped_dfs: t.List"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def create_dataframe_from_rows(table) -> pd.DataFrame:\n",
    "    data = []\n",
    "    \n",
    "    keys = None\n",
    "    for i, row in enumerate(table.rows):\n",
    "        text = (cell.text for cell in row.cells)\n",
    "    \n",
    "        if i == 0:\n",
    "            keys = tuple(text)\n",
    "            continue\n",
    "        row_data = dict(zip(keys, text))\n",
    "        data.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def processing_name(name: str) -> str:\n",
    "    \"\"\"ÐŸÐ¾Ð´Ð¿Ð¸ÑÑŒ Ð¿ÐµÑ€ÐµÐ´ Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÐµÐ¹ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð½Ð° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… ÑÑ‚Ñ€Ð¾ÐºÐ°Ñ…, Ð¿Ð¾ÐºÐ° Ð´Ñ€Ð¾Ð¿Ð½ÐµÐ¼ Ð²ÑÑ‘ ÐºÑ€Ð¾Ð¼Ðµ Ð¿ÐµÑ€Ð²Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸\"\"\"\n",
    "    # return name.lower().split(\"\\n\")[0].strip()\n",
    "    return name.lower().replace(\"\\n\", \" \")\n",
    "\n",
    "def processing_folder_name(raw_folder_name: str) -> str:\n",
    "    folder_name = re.findall(r\"\\d\\.\\s+(.*)\", raw_folder_name)\n",
    "    if not folder_name:\n",
    "        return raw_folder_name\n",
    "    else:\n",
    "        return folder_name[-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def get_docx(path: str) -> t.List[str]:\n",
    "    for f in sorted(os.listdir(path)):\n",
    "        if not \"R\" in f or not f.endswith(\"docx\"):\n",
    "            continue\n",
    "        yield os.path.join(path, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "[*get_docx(\"../raw/2021/\")]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "docx_file = \"/home/urev/projects/master-medicine/raw/2013/R-1.docx\"\n",
    "\n",
    "def get_dfs_from_docx(docx_file: str) -> ParseResult:\n",
    "    \"\"\"\n",
    "    Ð¢Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð±Ñ‹Ð²Ð°ÑŽÑ‚ Ð´Ð²ÑƒÑ… Ð²Ð¸Ð´Ð¾Ð²:\n",
    "    - ÑƒÐ·ÐºÐ¸Ðµ Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸ÐµÐ¼ Ð² Ð²Ñ‹ÑÐ¾Ñ‚Ñƒ (Ñƒ Ñ‚Ð°ÐºÐ¸Ñ… Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð½Ð¾ 'ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð°Ð±Ð». X.X') - ÑÑ‚Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐºÐ»ÐµÑÑ‚ÑÑ\n",
    "    - ÑˆÐ¸Ñ€Ð¾ÐºÐ¸Ðµ Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸ÐµÐ¼ Ð² ÑˆÐ¸Ñ€Ð¸Ð½Ñƒ (Ñ‚Ð°ÐºÐ¸Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð½Ðµ Ð¿Ð°Ñ€ÑÑÑ‚ÑÑ, Ð¸Ñ… Ð½Ð°Ð´Ð¾ ÐºÐ»ÐµÐ¸Ñ‚ÑŒ). Ð§Ñ‚Ð¾Ð±Ñ‹ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ ÑÐºÐ»ÐµÐ¸Ñ‚ÑŒ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÑƒ Ð² Ñ„Ð°Ð¹Ð»:\n",
    "     - ÐŸÐ¾Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð½Ð°Ð¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹, Ñ‚Ðº ÑÐºÐ¾Ñ€ÐµÐµ Ð²ÑÐµÐ³Ð¾ Ð¾Ð½Ð¾ Ñ‚Ð¾Ð¶Ðµ ÑˆÐ¸Ñ€Ð¾ÐºÐ¾Ðµ Ð¸ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¾ Ð½Ð° Ð´Ð²Ðµ Ñ‡Ð°ÑÑ‚Ð¸\n",
    "     - Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð¸Ð¼ÐµÐ½ÑƒÑŽÑ‚ÑÑ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ Ð³Ð»Ð°Ð²Ð½Ð¾Ð¹, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 2.76 + ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð°Ñ Ð½ÑƒÐ¼ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· Ñ‚Ð¾Ñ‡ÐºÑƒ -> 2.76.1\n",
    "     - Ð½Ð¾Ð²Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° (Ñ„Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ñ‡Ð°ÑÑ‚ÑŒ Ð¿Ð¾ Ð²Ñ‹ÑÐ¾Ñ‚Ðµ) Ð¾Ð±Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚ÑÑ ÐºÐ°Ðº 2.76.1\n",
    "     - ÐµÑ‘ Ð²ÐµÑ€Ñ‚Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð¼ÐµÑ‡Ð°ÐµÑ‚ÑÑ ÐºÐ°Ðº Ð’Ð•Ð Ð¢Ð˜ÐšÐÐ›Ð¬ÐÐžÐ• Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð°Ð±Ð». 2.76.1\n",
    "\n",
    "    ÐŸÑ€Ð¸ Ñ‚Ð°ÐºÐ¾Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐµ: ÑƒÐ·ÐºÐ¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ ÑÐ°Ð¼Ð¸ ÑÐºÐ»ÐµÑÑ‚ÑÑ Ð² Ð¾Ð´Ð½Ñƒ Ð¾Ð±Ñ‰ÑƒÑŽ, ÑˆÐ¸Ñ€Ð¾ÐºÐ¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ ÑÐºÐ»ÐµÑÑ‚ÑÑ Ð¿Ð¾ ÑˆÐ¸Ñ€Ð¸Ð½Ðµ, \n",
    "    Ð¿Ð¾ Ð²Ñ‹ÑÐ¾Ñ‚Ðµ Ð½Ð°Ð´Ð¾ Ð±ÑƒÐ´ÐµÑ‚ ÐºÐ»ÐµÐ¸Ñ‚ÑŒ Ð¿Ð¾ÑÐ»Ðµ (2.76 + 2.76.1 + 2.76.2 Ð¸ Ñ‚Ð´)\n",
    "    \"\"\"\n",
    "    document = Document(docx_file)\n",
    "    \n",
    "    dfs = {}\n",
    "    last_obj_stack = []\n",
    "    last_table_obj = None\n",
    "    raw_folder_name = None\n",
    "    skipped_dfs = {}\n",
    "    \n",
    "    for idx, c in enumerate(document.sections[0].iter_inner_content()):\n",
    "        if isinstance(c, Paragraph) and idx == 0:\n",
    "            raw_folder_name = c.text\n",
    "            print(f\"raw_folder_name: {raw_folder_name}\")\n",
    "        if isinstance(c, Paragraph):\n",
    "            # print(f\"--> {c.text}\")\n",
    "            pass\n",
    "        if isinstance(c, Table):\n",
    "            tmp = create_dataframe_from_rows(table=c)\n",
    "    \n",
    "            last_obj = last_obj_stack.pop()\n",
    "            name = last_obj.text.lower()\n",
    "            print(f\"--> Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð°: {name}\")\n",
    "    \n",
    "            pattern_name = \"\\d\\.\\d+\"\n",
    "\n",
    "            if \"Ð¿Ñ€Ð¾Ð¿ÑƒÑÐº\" in name:\n",
    "                print(f\"SKIP, Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð° Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ° Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°: {name}\")\n",
    "                tmp.name = name\n",
    "\n",
    "                skipped_dfs[tmp.name] = tmp\n",
    "                \n",
    "                display(tmp.head())\n",
    "                continue\n",
    "            \n",
    "            if re.findall(pattern_name, name):\n",
    "                table_number = re.findall(pattern_name, name)[-1]\n",
    "                print(f\"âœ… Ð’ Ð¸Ð¼ÐµÐ½Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ (Ð¾Ð±ÑŠÐµÐºÑ‚ Ð¿ÐµÑ€ÐµÐ´ Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÐµÐ¹) ÐµÑÑ‚ÑŒ Ñ†Ð¸Ñ„Ñ€Ñ‹: {table_number} -> ÑÑ‚Ð¾ Ð¸Ð»Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ!\")\n",
    "            else:\n",
    "                print(f\"ðŸ”´ Ð’ Ð¸Ð¼ÐµÐ½Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ (Ð¾Ð±ÑŠÐµÐºÑ‚ Ð¿ÐµÑ€ÐµÐ´ Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÐµÐ¹) Ð½ÐµÑ‚ Ñ†Ð¸Ñ„Ñ€, Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð²Ð·ÑÑ‚ÑŒ ÐµÑ‰Ðµ Ð¾Ð´Ð¸Ð½ Ð¾Ð±ÑŠÐµÐºÑ‚ Ð¸Ð· ÑÑ‚ÐµÐºÐ° (Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¸Ð¼Ñ Ð½Ð° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… ÑÑ‚Ñ€Ð¾ÐºÐ°Ñ…)\")\n",
    "                if last_obj_stack != []:\n",
    "                    # ÐµÑÐ»Ð¸ ÑÑ‚ÐµÐº Ð½Ðµ Ð¿ÑƒÑÑ‚Ð¾Ð¹\n",
    "                    last_obj = last_obj_stack.pop()\n",
    "\n",
    "                    if isinstance(last_obj, Table):\n",
    "                        print(f\"ðŸ‘€ÐŸÑ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¾Ð±ÑŠÐµÐºÑ‚ = Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°, Ð¡ÐšÐžÐ Ð•Ð• Ð’Ð¡Ð•Ð“Ðž ÐÐ£Ð–ÐÐ Ð ÐÐ—ÐœÐ•Ð¢ÐšÐ!\")\n",
    "                    elif isinstance(last_obj, Paragraph):\n",
    "                        print(f\"ðŸ‘€ ÐŸÑ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¾Ð±ÑŠÐµÐºÑ‚ = Ð¿Ð°Ñ€Ð°Ð³Ñ€Ð°Ñ„ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼, Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¸Ð¼Ñ....\")\n",
    "                    \n",
    "                        name = last_obj.text.lower()\n",
    "                        if not re.findall(pattern_name, name):\n",
    "                            print(f\"â›”ï¸ Ð’ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ¼ Ð¾Ð±ÑŠÐµÐºÑ‚Ðµ, Ñ‚Ð°Ðº Ð¶Ðµ Ð½ÐµÑ‚ Ñ†Ð¸Ñ„Ñ€, ÑÑ‚Ð° Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ð½Ð°Ð¼ Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚! name: {name}\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(f\"âœ… Ð˜Ð¼Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¾: {name}\")\n",
    "                else:\n",
    "                    name = \"unknown\"\n",
    "                    print(\"â›”ï¸ Ð¡Ñ‚ÐµÐº Ð¿ÑƒÑÑ‚Ð¾Ð¹!\")\n",
    "                print(f\"â˜ï¸ Ð’ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ¼ obj Ð½ÐµÑ‚ Ñ†Ð¸Ñ„Ñ€, Ð±ÐµÑ€ÐµÐ¼ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð¸Ð· ÑÑ‚ÐµÐºÐ° (Ð¸Ð»Ð¸ 'unknown'), Ð¸Ð¼Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹: {name}\")\n",
    "                \n",
    "            tmp.name = processing_name(name)\n",
    "            \n",
    "            if getattr(last_obj, \"text\") and \"Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ\" in last_obj.text.lower() and \"Ð²ÐµÑ€Ñ‚Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ\" not in last_obj.text.lower():\n",
    "                print(f\"\\t--> ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹: {last_table_obj.name}\")\n",
    "                tmp = pd.concat([last_table_obj, tmp])\n",
    "                tmp.name = last_table_obj.name\n",
    "                display(tmp.sample(5))\n",
    "            elif getattr(last_obj, \"text\") and \"Ð²ÐµÑ€Ñ‚Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ\" in last_obj.text.lower():\n",
    "                print(f\"ðŸ”« Ð­Ñ‚Ð¾ Ð²ÐµÑ€Ñ‚Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹: {last_table_obj.name}\")\n",
    "                tmp = pd.concat([last_table_obj, tmp], axis=\"columns\")\n",
    "                tmp.name = last_table_obj.name\n",
    "                display(tmp.sample(5))\n",
    "            else:\n",
    "                display(tmp.head())\n",
    "    \n",
    "            dfs[tmp.name] = tmp\n",
    "            \n",
    "            last_table_obj = tmp\n",
    "    \n",
    "        last_obj_stack.append(c)\n",
    "\n",
    "    return ParseResult(\n",
    "        folder_name=processing_folder_name(raw_folder_name),\n",
    "        dfs=[[df] for df in dfs.values()],\n",
    "        skipped_dfs=[[df] for df in skipped_dfs.values()]\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "_parse_obj = get_dfs_from_docx(docx_file=\"../raw/2015/R-1.docx\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "_parse_obj.folder_name"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "year = 2021\n",
    "for doc_path in get_docx(f\"../raw/{year}/\"):\n",
    "    if re.match(r'.*r-[8-9].*', doc_path.lower()):\n",
    "        continue\n",
    "    print(doc_path)\n",
    "    parse_obj = get_dfs_from_docx(docx_file=doc_path)\n",
    "\n",
    "    folder_name = doc_path.split(\"/\")[-1].split(\".\")[0].lower() if not parse_obj.folder_name else parse_obj.folder_name\n",
    "\n",
    "    for dfs in (parse_obj.dfs,\n",
    "               parse_obj.skipped_dfs):\n",
    "        save(list_of_dfs=dfs,\n",
    "             year=year,\n",
    "             folder=f\"../src/{year}/{folder_name}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
